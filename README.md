# ğŸ‘ï¸ Eye Detection & Iris Segmentation Pipeline

This project implements a **two-stage deep learning pipeline** for detecting the eye region in an image and performing iris segmentation.  
It combines **YOLOv11n** ğŸ¦¾ object detection with **U-Net** ğŸ§© semantic segmentation using various encoder backbones.

---

## ğŸ“Œ Project Overview
The pipeline follows these main steps:

1. **ğŸ” Eye Detection**  
   - A custom-trained YOLOv11n model detects the eye region in the input image.  
   - The detected bounding box is used to crop the eye area.

2. **ğŸ›  Data Preparation for Segmentation**  
   - Cropped eye images are prepared for segmentation training.  
   - Augmentation techniques are applied using **Albumentations** ğŸ¨ and **imgaug** to improve robustness.

3. **ğŸ¯ Iris Segmentation**  
   - The cropped eye image is passed to a U-Net segmentation model with various encoders (`ResNest152`, `DenseNet161`, `InceptionResNetV2`, `EfficientNet-b3`).  
   - The predicted mask is generated and visualized.

4. **âš™ï¸ Pipeline Integration**  
   - All steps are combined into a single `pipeline()` function that runs detection â†’ cropping â†’ segmentation â†’ visualization.

---

## ğŸ“‚ Dataset Preparation
- **ğŸ“· Detection Dataset**: Labeled in YOLO format, verified with **LabelImg**.  
- **ğŸ­ Segmentation Dataset**: Eye crops masked using **Roboflow** for iris segmentation.  
- **ğŸ¨ Augmentation**: Applied using **Albumentations** and `imgaug` to simulate variations in lighting, rotation, and quality.  
- **ğŸ”„ Pretrained Fine-tuning**: YOLO model retrained starting from a previously trained model for improved performance.

---

## ğŸ“Š Model Performance Summary
| ğŸ§  Model             | ğŸ“ˆ Train Acc. | ğŸ“Š Val Acc. | ğŸ“ IoU   | ğŸ† Best Metric      |
|----------------------|---------------|------------|---------|---------------------|
| ResNest152           | 99.72%        | 99.52%     | ~0.485  | Best F1 Score       |
| DenseNet161          | High          | High       | ~0.485  | Similar results     |
| InceptionResNetV2    | High          | High       | ~0.485  | Lowest Val Loss     |
| EfficientNet-b3      | High          | Slightly lower | ~0.485 | Low Train Loss  |

---

## ğŸ“ Project Structure
```bash
â”œâ”€â”€ crop_eyes.py                 # âœ‚ï¸ Crops detected eyes from YOLO predictions
â”œâ”€â”€ eye.yaml                     # ğŸ“œ YOLOv11n model configuration
â”œâ”€â”€ eyes.yaml                    # ğŸ“œ YOLOv11n dataset configuration
â”œâ”€â”€ pipeline.py                  # ğŸ”„ Main detection â†’ segmentation pipeline
â”œâ”€â”€ predict_segmentation.py      # ğŸ–¼ Runs segmentation on cropped eye images
â”œâ”€â”€ segmentation.py              # ğŸ§© Defines/trains segmentation models (U-Net + encoders)
â”œâ”€â”€ show_mask.py                 # ğŸ‘ Visualizes predicted segmentation masks
â”œâ”€â”€ test_segmentation.py         # ğŸ§ª Tests segmentation model performance
â”œâ”€â”€ train_w_pretained.py         # ğŸ“ˆ Trains YOLO model using pretrained weights
â”œâ”€â”€ to_seg.py                    # ğŸ”„ Converts detection outputs into segmentation dataset format
â”œâ”€â”€ aug_for_seg_imgaug.py        # ğŸ¨ Applies imgaug-based augmentations for segmentation data
```
---

## âš™ï¸ Installation
Install dependencies:
```bash
pip install torch torchvision ultralytics albumentations imgaug opencv-python segmentation-models-pytorch
```
---

## ğŸš€ YOLOv11n Eye Detection Training   
This project uses YOLOv11n via the Ultralytics Python API for training the eye detection model.
- **ğŸ“Œ Before training, ensure:
  	â€¢	eye.yaml is placed in:
```bash
/Users/<username>/Desktop/y/ultralytics/ultralytics/cfg/models/11/eye.yaml
```
â€¢	eyes.yaml is placed in:
```bash
/Users/<username>/Desktop/y/ultralytics/ultralytics/cfg/datasets/eyes.yaml
```
â€¢	Dataset paths in eyes.yaml point to your train/validation folders.   
###ğŸ’» Example Training Script
```bash
from ultralytics import YOLO

# Load YOLOv11n model with custom architecture
model = YOLO("/Users/<username>/Desktop/y/ultralytics/ultralytics/cfg/models/11/eye.yaml")

# Train model using dataset configuration
results = model.train(
    model=model,
    data="/Users/<username>/Desktop/y/ultralytics/ultralytics/cfg/datasets/eyes.yaml",
    epochs=10,
    imgsz=614,
    batch=8,
    device='mps'  # âš¡ Use MPS for Apple Silicon
)
```

---

## ğŸ”„ Workflow
- **1ï¸âƒ£ Crop Eyes from Images
```bash
python crop_eyes.py --source /path/to/images --weights best.pt --output cropped_eyes/
```
- **2ï¸âƒ£ Prepare Data for Segmentation
```bash
python to_seg.py --input cropped_eyes/ --output segmentation_dataset/
```
- **3ï¸âƒ£ Apply Augmentation for Segmentation Dataset
```bash
python aug_for_seg_imgaug.py --input segmentation_dataset/ --output segmentation_aug/
```
- **4ï¸âƒ£ Train Segmentation Model
```bash
python segmentation.py --encoder resnest152 --epochs 50
```
- **5ï¸âƒ£ Run the Full Detection â†’ Segmentation Pipeline
```bash
python pipeline.py --image input.jpg --detection_weights best.pt --segmentation_weights best_seg.pth
```
- **6ï¸âƒ£ Visualize Segmentation Mask
```bash
python show_mask.py --image input.jpg --mask mask.png
```


---

## ğŸ“ Notes
- **ğŸ“‚ Place trained YOLO weights (best.pt) in the detection script directory before running. 
- **ğŸ“‚ Place trained segmentation weights (best_seg.pth) in the segmentation scripts directory before running.
- **âš™ï¸ Adjust imgsz and batch according to your hardware.
- **ğŸŒ For better real-world performance, increase dataset diversity with lighting, angle, and quality variations.

---
